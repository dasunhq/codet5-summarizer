{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyNuP4cPEJfpJaM20OzGXoMO"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"ae332726c9b34f5eb15a9fd32ce6a1bb":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e110f39229d44d7da8bbfa54af75dda7","IPY_MODEL_c359bf4ac7424372b2c0d05502333d5e","IPY_MODEL_c78a80c9e33049e3ba0256fcb370000d"],"layout":"IPY_MODEL_71aec8f2f4aa4e778fef59ed50dc61e2"}},"e110f39229d44d7da8bbfa54af75dda7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_40b63ae7034449fd9ee40ef3e8e4c226","placeholder":"​","style":"IPY_MODEL_5a8f4d86def74e55b6a7fb5715a4ff6e","value":"Map: 100%"}},"c359bf4ac7424372b2c0d05502333d5e":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4c20bd7c3ebe48e3b59ee702b4bd8feb","max":13914,"min":0,"orientation":"horizontal","style":"IPY_MODEL_c983cfb245be4a1183eab8c59f0f0488","value":13914}},"c78a80c9e33049e3ba0256fcb370000d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9d082dd0512c46a6aa411e8d692972f8","placeholder":"​","style":"IPY_MODEL_05779fa4d6da41da86262c1ada580cd6","value":" 13914/13914 [00:11&lt;00:00, 1455.18 examples/s]"}},"71aec8f2f4aa4e778fef59ed50dc61e2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"40b63ae7034449fd9ee40ef3e8e4c226":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5a8f4d86def74e55b6a7fb5715a4ff6e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4c20bd7c3ebe48e3b59ee702b4bd8feb":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c983cfb245be4a1183eab8c59f0f0488":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"9d082dd0512c46a6aa411e8d692972f8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"05779fa4d6da41da86262c1ada580cd6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"markdown","source":["## Step 01: Install required librairies"],"metadata":{"id":"op4uSxY-lqwQ"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"v-89bf4gk4mo","executionInfo":{"status":"ok","timestamp":1756893431308,"user_tz":-330,"elapsed":12097,"user":{"displayName":"Dasun Wickramasooriya","userId":"06842970482256517570"}},"outputId":"10ec7c63-14af-4272-fd67-598113295159"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (2.8.0+cu126)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.12/dist-packages (4.0.0)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.5)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (4.56.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch) (3.19.1)\n","Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch) (4.15.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch) (75.2.0)\n","Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch) (1.13.3)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch) (3.5)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch) (2025.3.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.80)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch) (9.10.2.21)\n","Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.4.1)\n","Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch) (11.3.0.4)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch) (10.3.7.77)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch) (11.7.1.2)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch) (12.5.4.2)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch) (0.7.1)\n","Requirement already satisfied: nvidia-nccl-cu12==2.27.3 in /usr/local/lib/python3.12/dist-packages (from torch) (2.27.3)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.77)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch) (12.6.85)\n","Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch) (1.11.1.6)\n","Requirement already satisfied: triton==3.4.0 in /usr/local/lib/python3.12/dist-packages (from torch) (3.4.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.0.2)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (18.1.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets) (2.32.4)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from datasets) (0.34.4)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from datasets) (25.0)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.12/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.22.0)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers) (0.6.2)\n","Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.12.15)\n","Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.24.0->datasets) (1.1.8)\n","Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.4.3)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2.5.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets) (2025.8.3)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2.9.0.post0)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets) (2025.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n","Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.4.0)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.7.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.6.4)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.2)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n"]}],"source":["!pip install torch datasets evaluate --upgrade transformers"]},{"cell_type":"markdown","source":["## Step 02: Check GPU availability"],"metadata":{"id":"55cad82il0Ii"}},{"cell_type":"code","source":["import torch\n","\n","if torch.cuda.is_available():\n","  device = torch.device(\"cuda\")\n","  print(\"GPU is available:\", torch.cuda.get_device_name(0))\n","else:\n","  device = torch.device(\"cpu\")\n","  print(\"GPU not availabl, using CPU\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d8W33qUllp5R","executionInfo":{"status":"ok","timestamp":1756893437771,"user_tz":-330,"elapsed":3765,"user":{"displayName":"Dasun Wickramasooriya","userId":"06842970482256517570"}},"outputId":"063af799-7683-4067-f19a-7a9ca05dd56d"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["GPU is available: Tesla T4\n"]}]},{"cell_type":"markdown","source":["## Step 03: Load Dataset"],"metadata":{"id":"o3xG1ByG2DCh"}},{"cell_type":"code","source":["from datasets import load_dataset\n","\n","ds = load_dataset(\"google/code_x_glue_ct_code_to_text\", \"python\")\n","\n","# preview dataset\n","print(ds)\n","print(\"Example entry:\")\n","print(ds['train'][0])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MFueSQT62BQP","executionInfo":{"status":"ok","timestamp":1756893740292,"user_tz":-330,"elapsed":1049,"user":{"displayName":"Dasun Wickramasooriya","userId":"06842970482256517570"}},"outputId":"9aba6f41-55e2-485d-e150-cd0420fc0d12"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["DatasetDict({\n","    train: Dataset({\n","        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n","        num_rows: 251820\n","    })\n","    validation: Dataset({\n","        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n","        num_rows: 13914\n","    })\n","    test: Dataset({\n","        features: ['id', 'repo', 'path', 'func_name', 'original_string', 'language', 'code', 'code_tokens', 'docstring', 'docstring_tokens', 'sha', 'url'],\n","        num_rows: 14918\n","    })\n","})\n","Example entry:\n","{'id': 0, 'repo': 'proycon/pynlpl', 'path': 'pynlpl/formats/folia.py', 'func_name': 'AbstractElement.settext', 'original_string': 'def settext(self, text, cls=\\'current\\'):\\n        \"\"\"Set the text for this element.\\n\\n        Arguments:\\n            text (str): The text\\n            cls (str): The class of the text, defaults to ``current`` (leave this unless you know what you are doing). There may be only one text content element of each class associated with the element.\\n        \"\"\"\\n        self.replace(TextContent, value=text, cls=cls)', 'language': 'python', 'code': 'def settext(self, text, cls=\\'current\\'):\\n        \"\"\"Set the text for this element.\\n\\n        Arguments:\\n            text (str): The text\\n            cls (str): The class of the text, defaults to ``current`` (leave this unless you know what you are doing). There may be only one text content element of each class associated with the element.\\n        \"\"\"\\n        self.replace(TextContent, value=text, cls=cls)', 'code_tokens': ['def', 'settext', '(', 'self', ',', 'text', ',', 'cls', '=', \"'current'\", ')', ':', 'self', '.', 'replace', '(', 'TextContent', ',', 'value', '=', 'text', ',', 'cls', '=', 'cls', ')'], 'docstring': 'Set the text for this element.\\n\\n        Arguments:\\n            text (str): The text\\n            cls (str): The class of the text, defaults to ``current`` (leave this unless you know what you are doing). There may be only one text content element of each class associated with the element.', 'docstring_tokens': ['Set', 'the', 'text', 'for', 'this', 'element', '.'], 'sha': '7707f69a91caaa6cde037f0d0379f1d42500a68b', 'url': 'https://github.com/proycon/pynlpl/blob/7707f69a91caaa6cde037f0d0379f1d42500a68b/pynlpl/formats/folia.py#L1357-L1364'}\n"]}]},{"cell_type":"markdown","source":["## Step 04: Load Model & Tokenizer"],"metadata":{"id":"77ZRE00v3-4m"}},{"cell_type":"code","source":["from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n","\n","model_name = \"Salesforce/codet5-small\"\n","tokenizer = AutoTokenizer.from_pretrained(model_name)\n","model = AutoModelForSeq2SeqLM.from_pretrained(model_name)\n","\n","model.to(device)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DdW7DLQw4CXc","executionInfo":{"status":"ok","timestamp":1756893758938,"user_tz":-330,"elapsed":14433,"user":{"displayName":"Dasun Wickramasooriya","userId":"06842970482256517570"}},"outputId":"5e279c5d-e8fa-4611-f1df-f2b26e10066c"},"execution_count":5,"outputs":[{"output_type":"execute_result","data":{"text/plain":["T5ForConditionalGeneration(\n","  (shared): Embedding(32100, 512)\n","  (encoder): T5Stack(\n","    (embed_tokens): Embedding(32100, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (decoder): T5Stack(\n","    (embed_tokens): Embedding(32100, 512)\n","    (block): ModuleList(\n","      (0): T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","              (relative_attention_bias): Embedding(32, 8)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","      (1-5): 5 x T5Block(\n","        (layer): ModuleList(\n","          (0): T5LayerSelfAttention(\n","            (SelfAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (1): T5LayerCrossAttention(\n","            (EncDecAttention): T5Attention(\n","              (q): Linear(in_features=512, out_features=512, bias=False)\n","              (k): Linear(in_features=512, out_features=512, bias=False)\n","              (v): Linear(in_features=512, out_features=512, bias=False)\n","              (o): Linear(in_features=512, out_features=512, bias=False)\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","          (2): T5LayerFF(\n","            (DenseReluDense): T5DenseActDense(\n","              (wi): Linear(in_features=512, out_features=2048, bias=False)\n","              (wo): Linear(in_features=2048, out_features=512, bias=False)\n","              (dropout): Dropout(p=0.1, inplace=False)\n","              (act): ReLU()\n","            )\n","            (layer_norm): T5LayerNorm()\n","            (dropout): Dropout(p=0.1, inplace=False)\n","          )\n","        )\n","      )\n","    )\n","    (final_layer_norm): T5LayerNorm()\n","    (dropout): Dropout(p=0.1, inplace=False)\n","  )\n","  (lm_head): Linear(in_features=512, out_features=32100, bias=False)\n",")"]},"metadata":{},"execution_count":5}]},{"cell_type":"markdown","source":["## Step 05: Preprocess Dataset"],"metadata":{"id":"nTvSOmHK7jrb"}},{"cell_type":"markdown","source":["Tokenize both **code(input)** and **docstring(labels)**:"],"metadata":{"id":"To5Afz7f7uU0"}},{"cell_type":"code","source":["max_source_length = 256\n","max_target_length = 128\n","\n","def preprocess_function(examples):\n","  inputs = examples[\"code\"]\n","  targets = examples[\"docstring\"]\n","\n","  model_inputs = tokenizer(inputs, max_length = max_source_length, truncation=True)\n","\n","  labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n","\n","  model_inputs[\"labels\"] = labels[\"input_ids\"]\n","\n","  return model_inputs\n","\n","tokenized_datasets = ds.map(preprocess_function,batched=True)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":49,"referenced_widgets":["ae332726c9b34f5eb15a9fd32ce6a1bb","e110f39229d44d7da8bbfa54af75dda7","c359bf4ac7424372b2c0d05502333d5e","c78a80c9e33049e3ba0256fcb370000d","71aec8f2f4aa4e778fef59ed50dc61e2","40b63ae7034449fd9ee40ef3e8e4c226","5a8f4d86def74e55b6a7fb5715a4ff6e","4c20bd7c3ebe48e3b59ee702b4bd8feb","c983cfb245be4a1183eab8c59f0f0488","9d082dd0512c46a6aa411e8d692972f8","05779fa4d6da41da86262c1ada580cd6"]},"id":"tPnkbLNI7mhP","executionInfo":{"status":"ok","timestamp":1756893792213,"user_tz":-330,"elapsed":11671,"user":{"displayName":"Dasun Wickramasooriya","userId":"06842970482256517570"}},"outputId":"689a4a2b-1b28-4e43-db78-6a9b80dca276"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["Map:   0%|          | 0/13914 [00:00<?, ? examples/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ae332726c9b34f5eb15a9fd32ce6a1bb"}},"metadata":{}}]},{"cell_type":"markdown","source":["## Step 06: Set Up Training     "],"metadata":{"id":"knJZL8gj-IzN"}},{"cell_type":"code","metadata":{"id":"3f40ac7e","executionInfo":{"status":"ok","timestamp":1756895194456,"user_tz":-330,"elapsed":1706,"user":{"displayName":"Dasun Wickramasooriya","userId":"06842970482256517570"}}},"source":["from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments, DataCollatorForSeq2Seq\n","import evaluate\n","import numpy as np\n","\n","# Data collator\n","data_collator = DataCollatorForSeq2Seq(tokenizer, model=model)\n","\n","# Evaluation metric\n","bleu = evaluate.load(\"bleu\")\n","\n","def compute_metrics(eval_pred):\n","    predictions, labels = eval_pred\n","    # Ensure labels are converted to numpy arrays if they are not already\n","    if not isinstance(labels, np.ndarray):\n","        labels = labels.numpy()\n","\n","    # Replace -100 in labels as we can't decode them.\n","    # We are only interested in the part that was not padded.\n","    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n","\n","    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n","    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n","\n","    # Ensure that the lengths of predictions and references match\n","    # This might be necessary if skip_special_tokens removed tokens from one but not the other\n","    # In this specific case, we expect them to align after handling -100\n","    # If misalignment persists, further debugging would be needed\n","\n","    return bleu.compute(predictions=decoded_preds, references=[[l] for l in decoded_labels])\n","\n","# Training arguments\n","training_args = Seq2SeqTrainingArguments(\n","    output_dir=\"./codet5-summarizer\",\n","    eval_strategy=\"epoch\",\n","    learning_rate=5e-5,\n","    per_device_train_batch_size=8,\n","    per_device_eval_batch_size=8,\n","    num_train_epochs=3,\n","    weight_decay=0.01,\n","    save_total_limit=2,\n","    logging_dir='./logs',\n","    logging_steps=100,\n","    predict_with_generate=True,\n","    fp16=True,\n","    report_to=[],\n",")\n","\n","# Trainer\n","trainer = Seq2SeqTrainer(\n","    model=model,\n","    args=training_args,\n","    train_dataset=tokenized_datasets[\"train\"].select(range(5000)),\n","    eval_dataset=tokenized_datasets[\"validation\"].select(range(500)),\n","    data_collator=data_collator,\n","    compute_metrics=compute_metrics\n",")"],"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## Step 07: Train the Model"],"metadata":{"id":"Dkb2aojXD1ro"}},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":275},"id":"baf6d2e5","executionInfo":{"status":"ok","timestamp":1756895569292,"user_tz":-330,"elapsed":361004,"user":{"displayName":"Dasun Wickramasooriya","userId":"06842970482256517570"}},"outputId":"b6956dbd-7891-49ac-d180-286d8104de40"},"source":["trainer.train()"],"execution_count":23,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='1875' max='1875' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [1875/1875 06:00, Epoch 3/3]\n","    </div>\n","    <table border=\"1\" class=\"dataframe\">\n","  <thead>\n"," <tr style=\"text-align: left;\">\n","      <th>Epoch</th>\n","      <th>Training Loss</th>\n","      <th>Validation Loss</th>\n","      <th>Bleu</th>\n","      <th>Precisions</th>\n","      <th>Brevity Penalty</th>\n","      <th>Length Ratio</th>\n","      <th>Translation Length</th>\n","      <th>Reference Length</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <td>1</td>\n","      <td>0.011300</td>\n","      <td>0.048004</td>\n","      <td>0.013353</td>\n","      <td>[0.9909581218274112, 0.988973121984838, 0.9879336349924586, 0.9866777685262281]</td>\n","      <td>0.013507</td>\n","      <td>0.188517</td>\n","      <td>6304</td>\n","      <td>33440</td>\n","    </tr>\n","    <tr>\n","      <td>2</td>\n","      <td>0.019000</td>\n","      <td>0.046482</td>\n","      <td>0.013415</td>\n","      <td>[0.9912822951339356, 0.9893269065243587, 0.9883217178376342, 0.9871075067581618]</td>\n","      <td>0.013564</td>\n","      <td>0.188666</td>\n","      <td>6309</td>\n","      <td>33440</td>\n","    </tr>\n","    <tr>\n","      <td>3</td>\n","      <td>0.016800</td>\n","      <td>0.042820</td>\n","      <td>0.013423</td>\n","      <td>[0.9911251980982567, 0.9891566265060241, 0.988135593220339, 0.9869022869022869]</td>\n","      <td>0.013575</td>\n","      <td>0.188696</td>\n","      <td>6310</td>\n","      <td>33440</td>\n","    </tr>\n","  </tbody>\n","</table><p>"]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["TrainOutput(global_step=1875, training_loss=0.019458872350056965, metrics={'train_runtime': 360.8194, 'train_samples_per_second': 41.572, 'train_steps_per_second': 5.197, 'total_flos': 1008175882174464.0, 'train_loss': 0.019458872350056965, 'epoch': 3.0})"]},"metadata":{},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"c13b70ff"},"source":["## Step 08: Evaluate the Model"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":287},"id":"e8cd639a","executionInfo":{"status":"ok","timestamp":1756895788354,"user_tz":-330,"elapsed":20717,"user":{"displayName":"Dasun Wickramasooriya","userId":"06842970482256517570"}},"outputId":"c73bc55b-bb6d-43a0-c141-7da60e0f8f71"},"source":["trainer.evaluate()"],"execution_count":24,"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","    <div>\n","      \n","      <progress value='63' max='63' style='width:300px; height:20px; vertical-align: middle;'></progress>\n","      [63/63 00:20]\n","    </div>\n","    "]},"metadata":{}},{"output_type":"execute_result","data":{"text/plain":["{'eval_loss': 0.04281972721219063,\n"," 'eval_bleu': 0.013423361221876786,\n"," 'eval_precisions': [0.9911251980982567,\n","  0.9891566265060241,\n","  0.988135593220339,\n","  0.9869022869022869],\n"," 'eval_brevity_penalty': 0.013575011524885359,\n"," 'eval_length_ratio': 0.18869617224880383,\n"," 'eval_translation_length': 6310,\n"," 'eval_reference_length': 33440,\n"," 'eval_runtime': 20.7061,\n"," 'eval_samples_per_second': 24.147,\n"," 'eval_steps_per_second': 3.043,\n"," 'epoch': 3.0}"]},"metadata":{},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"7f9cae23"},"source":["## Step 09: Inference"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"33c83910","executionInfo":{"status":"ok","timestamp":1756896032137,"user_tz":-330,"elapsed":2723,"user":{"displayName":"Dasun Wickramasooriya","userId":"06842970482256517570"}},"outputId":"db7f0b7a-162c-4427-fabd-7e70ee07d5e9"},"source":["# Example code snippet for inference\n","code_snippet = \"\"\"\n","import random\n","\n","# A list of greetings\n","greetings = [\"Hello\", \"Hi\", \"Hey\", \"Greetings\", \"Welcome\"]\n","\n","# Get the user's name\n","name = input(\"Please enter your name: \")\n","\n","# A conditional statement to check if the user entered a name\n","if name:\n","    # A for loop to print a random greeting five times\n","    for i in range(5):\n","        # Select a random greeting from the list\n","        greeting = random.choice(greetings)\n","        # Print the personalized greeting\n","        print(f\"{greeting}, {name}!\")\n","else:\n","    # A different message if no name was entered\n","    print(\"Hello there! You didn't enter a name.\")\n","\n","# A final message\n","print(\"\\nThis is a simple Python script.\")\n","print(\"It demonstrates lists, loops, conditionals, and user input.\")\n","\n","# End of script\n","\"\"\"\n","\n","# Tokenize the code snippet\n","input_ids = tokenizer(code_snippet, return_tensors=\"pt\", max_length=max_source_length, truncation=True).input_ids.to(device)\n","\n","# Generate the docstring\n","generated_ids = model.generate(input_ids, max_length=max_target_length)\n","generated_docstring = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n","\n","print(\"Generated Docstring:\", generated_docstring)"],"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["Generated Docstring: A list of greetings\n","greetings = [\"Hello\", \"Hi\", \"Hey\", \"Greetings\", \"Welcome\"]\n","\n","# Get the user's name\n","name = input(\"Please enter your name: \")\n","\n","# A conditional statement to check if the user entered a name\n","if name:\n","    # A for loop to print a random greeting five times\n","    for i in range(5):\n","        # Select a random greeting from the list\n","        greeting = random.choice(greetings)\n","        # Print the personalized greeting\n","        print\n"]}]}]}